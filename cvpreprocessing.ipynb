{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdtlpMCWKGKjfhgVEKe5hO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahilvaghasiyaa/-Market-Trend-classifier-and-analyzer/blob/main/cvpreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "def crop_and_detect_edges(image_path, crop_margin=3, output_size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Process a single image: crop it to the chart area, resize, and detect edges.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the input image\n",
        "        crop_margin: Margin to apply during cropping\n",
        "        output_size: Output image size\n",
        "\n",
        "    Returns:\n",
        "        edges: Edge-detected, cropped chart\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Check if image was loaded properly\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply binary threshold (detect chart area)\n",
        "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find contours (detect chart boundary)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Check if any contours were found\n",
        "    if not contours:\n",
        "        print(f\"No contours found in image: {image_path}\")\n",
        "        # If no contours, just resize the original image and apply edge detection\n",
        "        resized = cv2.resize(img, output_size, interpolation=cv2.INTER_AREA)\n",
        "        gray_resized = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
        "        blurred = cv2.GaussianBlur(gray_resized, (5, 5), 0)\n",
        "        edges = cv2.Canny(blurred, threshold1=20, threshold2=100)\n",
        "        return edges\n",
        "\n",
        "    # Find bounding box of the largest contour (chart area)\n",
        "    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "\n",
        "    # Slightly adjust the crop to remove extra border\n",
        "    x = max(0, x + crop_margin)\n",
        "    y = max(0, y + crop_margin)\n",
        "    w = max(0, w - 2 * crop_margin)\n",
        "    h = max(0, h - 2 * crop_margin)\n",
        "\n",
        "    # Crop the chart region\n",
        "    cropped_chart = img[y:y+h, x:x+w]\n",
        "\n",
        "    # Resize cropped image to maintain fixed size\n",
        "    cropped_chart_resized = cv2.resize(cropped_chart, output_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Convert to grayscale for edge detection\n",
        "    cropped_gray = cv2.cvtColor(cropped_chart_resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian Blur to reduce noise\n",
        "    blurred_gray = cv2.GaussianBlur(cropped_gray, (5, 5), 0)\n",
        "\n",
        "    # Apply Canny Edge Detection\n",
        "    edges = cv2.Canny(blurred_gray, threshold1=20, threshold2=100)\n",
        "\n",
        "    return edges\n",
        "\n",
        "def process_folder(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Process all images in a folder and save to output folder.\n",
        "\n",
        "    Args:\n",
        "        input_folder: Folder containing input images\n",
        "        output_folder: Folder to save processed images\n",
        "    \"\"\"\n",
        "    # Check if input folder exists\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"Input folder not found: {input_folder}\")\n",
        "        return\n",
        "\n",
        "    # Get all image files\n",
        "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No image files found in {input_folder}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(image_files)} images to process\")\n",
        "\n",
        "    # Process each image\n",
        "    for image_file in tqdm(image_files):\n",
        "        # Input and output paths\n",
        "        input_path = os.path.join(input_folder, image_file)\n",
        "\n",
        "        # Keep the same file name for output (maintain indexes)\n",
        "        output_path = os.path.join(output_folder, image_file)\n",
        "\n",
        "        # Process image\n",
        "        edges = crop_and_detect_edges(input_path)\n",
        "\n",
        "        # Save processed image if successful\n",
        "        if edges is not None:\n",
        "            cv2.imwrite(output_path, edges)\n",
        "\n",
        "def extract_zip_file(zip_path, extract_to):\n",
        "    \"\"\"\n",
        "    Extract a zip file to the specified directory\n",
        "\n",
        "    Args:\n",
        "        zip_path: Path to the zip file\n",
        "        extract_to: Directory to extract to\n",
        "    \"\"\"\n",
        "    print(f\"Extracting {zip_path} to {extract_to}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extraction completed\")\n",
        "\n",
        "def main():\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define paths\n",
        "    base_dir = \"/content/drive/MyDrive/FInancialMArkets data\"  # Using the path from your output\n",
        "\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(f\"Base directory not found: {base_dir}\")\n",
        "        return\n",
        "\n",
        "    # Create temp directory for extraction\n",
        "    temp_dir = \"/content/temp_data\"\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    # Create output directory - CHANGED TO \"datapreprocessed\"\n",
        "    output_base_dir = os.path.join(base_dir, \"datapreprocessed\")\n",
        "    os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "    # Check for zip files\n",
        "    zip_files = [f for f in os.listdir(base_dir) if f.lower().endswith('.zip')]\n",
        "\n",
        "    if not zip_files:\n",
        "        print(f\"No zip files found in {base_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found zip files: {zip_files}\")\n",
        "\n",
        "    # Process each zip file\n",
        "    for zip_file in zip_files:\n",
        "        # Extract zip file\n",
        "        zip_path = os.path.join(base_dir, zip_file)\n",
        "        extract_dir = os.path.join(temp_dir, zip_file[:-4])  # Remove .zip extension\n",
        "\n",
        "        # Skip if already extracted\n",
        "        if not os.path.exists(extract_dir):\n",
        "            extract_zip_file(zip_path, extract_dir)\n",
        "        else:\n",
        "            print(f\"{extract_dir} already exists, skipping extraction\")\n",
        "\n",
        "        # Get the class name (buy, sell, sideways)\n",
        "        class_name = zip_file[:-4]  # Remove .zip extension\n",
        "        if class_name.endswith(\"class\"):\n",
        "            prefix = class_name[:-5]  # Remove \"class\" suffix\n",
        "        else:\n",
        "            prefix = class_name\n",
        "\n",
        "        # Look for input and output folders\n",
        "        found_folders = os.listdir(extract_dir)\n",
        "\n",
        "        # Print the contents of the extracted directory to help with debugging\n",
        "        print(f\"Contents of {extract_dir}:\")\n",
        "        for item in found_folders:\n",
        "            print(f\"  - {item}\")\n",
        "\n",
        "            # If it's a directory, check its contents\n",
        "            item_path = os.path.join(extract_dir, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                try:\n",
        "                    subcontents = os.listdir(item_path)\n",
        "                    print(f\"    Contents: {subcontents[:5]}{'...' if len(subcontents) > 5 else ''}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"    Error reading directory: {e}\")\n",
        "\n",
        "        # Check for different folder structures\n",
        "        input_dir = None\n",
        "        output_dir = None\n",
        "\n",
        "        # Look for direct input/output folders\n",
        "        input_folder_name = f\"{prefix}input\"\n",
        "        output_folder_name = f\"{prefix}output\"\n",
        "\n",
        "        # First try direct structure\n",
        "        if input_folder_name in found_folders:\n",
        "            input_dir = os.path.join(extract_dir, input_folder_name)\n",
        "            print(f\"Found input directory: {input_dir}\")\n",
        "\n",
        "        if output_folder_name in found_folders:\n",
        "            output_dir = os.path.join(extract_dir, output_folder_name)\n",
        "            print(f\"Found output directory: {output_dir}\")\n",
        "\n",
        "        # If not found, try nested structure\n",
        "        if not input_dir:\n",
        "            for folder in found_folders:\n",
        "                folder_path = os.path.join(extract_dir, folder)\n",
        "                if os.path.isdir(folder_path):\n",
        "                    # Check if input folder is inside\n",
        "                    nested_input = os.path.join(folder_path, input_folder_name)\n",
        "                    if os.path.exists(nested_input):\n",
        "                        input_dir = nested_input\n",
        "                        print(f\"Found nested input directory: {input_dir}\")\n",
        "                        break\n",
        "\n",
        "        if not output_dir:\n",
        "            for folder in found_folders:\n",
        "                folder_path = os.path.join(extract_dir, folder)\n",
        "                if os.path.isdir(folder_path):\n",
        "                    # Check if output folder is inside\n",
        "                    nested_output = os.path.join(folder_path, output_folder_name)\n",
        "                    if os.path.exists(nested_output):\n",
        "                        output_dir = nested_output\n",
        "                        print(f\"Found nested output directory: {output_dir}\")\n",
        "                        break\n",
        "\n",
        "        # Create unique output directories for each class\n",
        "        processed_input_dir = os.path.join(output_base_dir, f\"{class_name}_{input_folder_name}\")\n",
        "        processed_output_dir = os.path.join(output_base_dir, f\"{class_name}_{output_folder_name}\")\n",
        "\n",
        "        os.makedirs(processed_input_dir, exist_ok=True)\n",
        "        os.makedirs(processed_output_dir, exist_ok=True)\n",
        "\n",
        "        # Process the input and output folders if found\n",
        "        if input_dir:\n",
        "            print(f\"Processing {input_folder_name}...\")\n",
        "            process_folder(input_dir, processed_input_dir)\n",
        "        else:\n",
        "            print(f\"Could not find {input_folder_name} folder in the extracted zip\")\n",
        "\n",
        "        if output_dir:\n",
        "            print(f\"Processing {output_folder_name}...\")\n",
        "            process_folder(output_dir, processed_output_dir)\n",
        "        else:\n",
        "            print(f\"Could not find {output_folder_name} folder in the extracted zip\")\n",
        "\n",
        "    # Clean up temp directory to save space\n",
        "    print(\"Cleaning up temporary files...\")\n",
        "    shutil.rmtree(temp_dir)\n",
        "\n",
        "    print(\"Image preprocessing completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEwYaG8awyHG",
        "outputId": "65369445-c68d-4d78-fa45-efa4aeaadf21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found zip files: ['buyclass.zip', 'sellclass.zip', 'sidewaysclass.zip']\n",
            "Extracting /content/drive/MyDrive/FInancialMArkets data/buyclass.zip to /content/temp_data/buyclass\n",
            "Extraction completed\n",
            "Contents of /content/temp_data/buyclass:\n",
            "  - buyoutput\n",
            "    Contents: ['outputimg4930.png', 'outputimg334.png', 'outputimg2348.png', 'outputimg4500.png', 'outputimg4957.png']...\n",
            "  - buyinput\n",
            "    Contents: ['inputimg1713.png', 'inputimg2118.png', 'inputimg2623.png', 'inputimg603.png', 'inputimg3525.png']...\n",
            "Found input directory: /content/temp_data/buyclass/buyinput\n",
            "Found output directory: /content/temp_data/buyclass/buyoutput\n",
            "Processing buyinput...\n",
            "Found 5000 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:23<00:00, 60.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing buyoutput...\n",
            "Found 5000 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:22<00:00, 60.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/FInancialMArkets data/sellclass.zip to /content/temp_data/sellclass\n",
            "Extraction completed\n",
            "Contents of /content/temp_data/sellclass:\n",
            "  - selloutput\n",
            "    Contents: ['outputimg4930.png', 'outputimg334.png', 'outputimg2348.png', 'outputimg4500.png', 'outputimg4957.png']...\n",
            "  - sellinput\n",
            "    Contents: ['inputimg1713.png', 'inputimg2118.png', 'inputimg2623.png', 'inputimg603.png', 'inputimg3525.png']...\n",
            "Found input directory: /content/temp_data/sellclass/sellinput\n",
            "Found output directory: /content/temp_data/sellclass/selloutput\n",
            "Processing sellinput...\n",
            "Found 5000 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:21<00:00, 61.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing selloutput...\n",
            "Found 5000 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:25<00:00, 58.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/FInancialMArkets data/sidewaysclass.zip to /content/temp_data/sidewaysclass\n",
            "Extraction completed\n",
            "Contents of /content/temp_data/sidewaysclass:\n",
            "  - sidewaysinput\n",
            "    Contents: ['inputimg1713.png', 'inputimg2118.png', 'inputimg2623.png', 'inputimg603.png', 'inputimg3525.png']...\n",
            "  - sidewaysoutput\n",
            "    Contents: ['outputimg4930.png', 'outputimg334.png', 'outputimg2348.png', 'outputimg4500.png', 'outputimg4957.png']...\n",
            "Found input directory: /content/temp_data/sidewaysclass/sidewaysinput\n",
            "Found output directory: /content/temp_data/sidewaysclass/sidewaysoutput\n",
            "Processing sidewaysinput...\n",
            "Found 5000 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:22<00:00, 60.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sidewaysoutput...\n",
            "Found 5000 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [01:22<00:00, 60.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning up temporary files...\n",
            "Image preprocessing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# ðŸ“‚ Specify the folder you want to save\n",
        "folder_to_save = \"sidewaysclass\"  # Change this to your folder name\n",
        "zip_filename = f\"{folder_to_save}.zip\"                                                            ######save\n",
        "\n",
        "# ðŸ“¦ Zip the folder\n",
        "shutil.make_archive(folder_to_save, 'zip', folder_to_save)\n",
        "\n",
        "# ðŸ“¥ Download the zipped folder\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "id": "gXW_AdPsT5Gs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}